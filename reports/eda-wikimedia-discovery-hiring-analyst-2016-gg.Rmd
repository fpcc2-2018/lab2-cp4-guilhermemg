---
title: "Wikimedia-Discovery-Hiring-Analyst-2016"
author: "Guilherme Gadelha"
date: "April 24, 2018"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    df_print: kable
    theme: united
    highlight: tango
---

# [Setup](#setup)

```{r setup, include=FALSE}

library(tidyverse)
library(lubridate)
library(here)

searches = read_csv(here::here("data/search_data.csv"))

head(searches)
names(searches)

```

To make this analysis we modified the original script that gets the data from wikimedia. The modifications are the following:

1. Original data slice size: 100000 observations (logged events)
2. Change of variable name from search_index to num_searches
3. Change of variable name from session_start_timestamp to first_event_timestamp
4. Change of variable name from session_start_date to first_event_date_time

The changes were made for improve the clarity and fidelity to the original dataset.

# [Question 1](#question1)
####*What is our daily overall clickthrough rate? How does it vary between the groups?*

## [Clean Data](#clean1)

We are interested in to calculate the daily overrall clickthrough rate. However, we have two particular problems:

1. In the same search session, the user can do multiple searches, so multiple search events are recorded associated with the same *session_id*.
2. The logged days do not correspond to intervals of exactly 24h to all the nine days in the dataset, we
need to balance the distribution of events over the days considering this fact.

### [Method](#clean1Method)

In order to clean and summarize the data we are dealing with, the following procedure was executed:

1. a new variable *day* was created to record the day of the session;
2. a grouping was made by session, day and group, summarizing the sum of clicks (*visitPage* events) by each row in the final dataset;

```{r clean_1}
sessions <- searches %>%
  mutate(hour = round_date(first_event_date_time, unit="hour")) %>% 
  group_by(session_id, hour, group) %>% 
  summarize(n_clicks = sum(num_clicks),
            n_sessions = n())

sessions %>% head()
```

A special care with sessions that could last from one day to another was observed, so we checked if there was any repeated *session_id*, but there was any.

```{r}
sessions %>% 
  distinct(session_id, .keep_all = T) %>% 
  dim()

sessions %>% 
  dim()
```

Grouping by session, we solve the first problem pointed out (same session with multiple searches in it).

For solve the second problem, we need to identify the days that have an incomplete log spectrum, i.e., the ones do not catch data in a 24 hour period corresponding to that day.

```{r}
n_sessions_df <- sessions %>% 
  group_by(hour, group) %>% 
  summarise(n_sessions = sum(n_sessions))

n_sessions_df %>% head()

n_sessions_df %>% 
  ggplot(aes(x = hour, y = n_sessions, color=group)) +
  geom_line() +
  geom_point() +
  facet_grid(~ group) +
  labs(x = "Hour",
       y = "Number of Sessions",
       colour = "Group")
```

As we can see in the figure below, the last day has missing hours, then we will filter it from our dataset, so we can calculate the daily clickthrough rate without any missing data.

```{r}
sessions <- sessions %>% 
  filter(day(hour) != 8)

sessions %>% dim()
```


Calculating and plotting the daily clickthrough rate (DCR)
```{r}
dcr_df <- sessions %>% 
  group_by(hour, group) %>% 
  summarise(dcr = sum(n_clicks)/sum(n_sessions))

dcr_df %>% head()

dcr_df %>% 
  ggplot(aes(x = hour, y = dcr, color=group)) +
  geom_point() +
  geom_line() +
  # geom_hline(aes(yintercept = mean(dcr_df$dcr), linetype="Mean"), colour="red") +
  facet_grid(~ group) +
  labs(x = "Hour",
       y = "Clickthrough Rate",
       color="Group")
       # linetype="Line Type")
```

The daily overrall clickthrough rate (DCR): _*the proportion of search sessions where the user clicked on one of the results displayed*_. 

For the group *a*, on the first four days the DCR is greather than or equal 0.40, that means around 40% of search sessions resulted in at least one click by the user with the intention of visiting a page listed on a SERP (search engine result page) returned to him after a search query.

It is important to make an observation: a good search engine returns to the user the best result in the firsts positions in the SERP, so he needs to click only once in the page and trigger an action of _visitPage_, logged by the wikimedia servers. In the following days, the clickthrough rate decreases, but stay around 0.40.

For the group *b*, the clickthrough rate is visibly smaller than the observed in the group *a*, arriving close to 0.2 on March 7th, the best day, but remaining bellow it in all the recorded days.


# [Question 2](#question2)
####*Which results do people tend to try first? How does it change day-to-day?*

## [Clean Data]({#clean2})

Here we are interested in *visitPage* events that happened after a search. The *visitPage* events are recorded in the *num_clicks* variable and the *position* of the result clicked first in the SERP (search engine result page) is recorded in *first_click* variable.

```{r clean_2}
sessions <- searches %>%
  mutate(day = round_date(first_event_date_time, unit="day")) %>% 
  filter(num_clicks >= 1)
```


```{r question_2, eval=FALSE}

searches %>% 
  mutate(day = day(session_start_date)) %>% 
  group_by(first_click) %>% 
  ggplot(aes(x = day, y = first_click, fill=day)) +
  geom_bar(stat="identity", position="dodge")

```


